{
 "metadata": {
  "name": "",
  "signature": "sha256:ef89e69ab8ce165dc005b06f3d1dced5db423f15c7e650a478088092a05998f4"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "spark_home = \"/usr/local/share/spark-0.9.0-incubating-bin-hadoop2\"\n",
      "os.environ['SPARK_HOME'] = spark_home\n",
      "import sys\n",
      "path_to_pyspark = os.path.join(spark_home,\"python\")\n",
      "sys.path.insert(0,path_to_pyspark)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyspark import SparkContext, SparkConf\n",
      "from collections import defaultdict\n",
      "import sys, operator, math, imp, os, uuid, ConfigParser, pyodbc\n",
      "import datetime as dt\n",
      "from multiprocessing import Pool\n",
      "import itertools as it\n",
      "import threading\n",
      "import networkx as nx\n",
      "import numpy \n",
      "import matplotlib . pyplot as plt\n",
      "#Constants for real pcmd string\n",
      "CONFIG_FILE = 'config.ini'\n",
      "FIELD_SERVING_CELL_ID_PRIMARY = 21\n",
      "FIELD_UE_LOCATION_CAPABILITY = 158\n",
      "FIELD_CELL_ID = 131\n",
      "START_CHAR_MEAS = '['\n",
      "END_CHAR_PCMD = '|'\n",
      "LENGTH_MEAS_DATA = 4\n",
      "FIELD_CELL_ID_MEAS = 2\n",
      "FIELD_RSRP_MEAS = 3\n",
      "RSRP_MIN = -140.0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "pcmdString = []\n",
      "with open('sample','rb') as csvfile:\n",
      "    ps = csv.reader(csvfile, delimiter =\";\")\n",
      "    \n",
      "    for row in ps:\n",
      "        pcmdString.append(row)\n",
      "#print pcmdString\n",
      "\n",
      "str =(pcmdString)\n",
      "print len(str)\n",
      " \n",
      "pcmdString[19][0]\n",
      "       "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "20\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "'6'"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def mapRealPCMDString(pcmdString):\n",
      "    servingCell, fieldDict = getFieldDictFromMeasRecord(pcmdString)\n",
      "    #debug\n",
      "    print \"We made it\"\n",
      "    if not fieldDict:\n",
      "\t\treturn []\n",
      "# Reset listOfMeasurements\n",
      "    listOfMeasurements = []\n",
      "    if servingCell in fieldDict.keys():\n",
      "\t\tserverDLRLC = fieldDict[servingCell][0][0]\n",
      "    else:\n",
      "\t\tserverDLRLC = -1\n",
      " \n",
      "    \n",
      "    for cellID in fieldDict.keys():\n",
      "        f1 = fieldDict[cellID][0][0]\n",
      "        f2 = fieldDict[cellID][0][1]\n",
      "        listOfMeasurements.append(((servingCell,cellID), \\\n",
      "\t\t\t(f1,f1*f1,serverDLRLC,serverDLRLC*serverDLRLC,f1*serverDLRLC,1)\t\\\n",
      "\t\t\t))\n",
      "\treturn listOfMeasurements"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "this function gets each field requested from the pcmd file\n",
      "\"\"\"\n",
      "def getFieldDictFromMeasRecord(pcmdString):\n",
      "    #assume this function is getting one record at a time\n",
      "    elementsOfPCMDString = pcmdString.split(\";\")\n",
      "    #elementsOfPCMDString =(pcmdString)\n",
      "              \n",
      "    cellID = elementsOfPCMDString[FIELD_CELL_ID -1]\n",
      "    servingCell = cellID\n",
      "    print cellID, secondaryFieldNum\n",
      "    secondaryFieldNum = elementsOfPCMDString[173-1]\n",
      "    \n",
      "    if secondaryFieldNum >= 2 and len(elementsOfPCMDString) >=299:\n",
      "        DLRLC_First = elementsOfPCMDString[285-1]\n",
      "    else:\n",
      "        print \"Shouldn't Hit this\"\n",
      "        return [], []\n",
      " \n",
      "    fieldDict =defaultdict(list)\n",
      "    fieldDict[cellID].append((float(DLRLC_First)))\n",
      "    return servingCell, fieldDict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "servingCell, fieldDict = getFieldDictFromMeasRecord(pcmdString[0])\n",
      "print servingCell, fieldDict\n",
      "servingCell, fieldDict = getFieldDictFromMeasRecord(pcmdString[8])\n",
      "print fieldDict\n",
      "for row in range(0, 8):\n",
      "    print row\n",
      "    servingCell, fieldDict = getFieldDictFromMeasRecord(pcmdString[row])\n",
      "    print fieldDict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AttributeError",
       "evalue": "'list' object has no attribute 'split'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-8-738c78e0c1f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mservingCell\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfieldDict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetFieldDictFromMeasRecord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpcmdString\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mservingCell\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfieldDict\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mservingCell\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfieldDict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetFieldDictFromMeasRecord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpcmdString\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mfieldDict\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-5-fdfd6d0f18df>\u001b[0m in \u001b[0;36mgetFieldDictFromMeasRecord\u001b[1;34m(pcmdString)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgetFieldDictFromMeasRecord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpcmdString\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m#assume this function is getting one record at a time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0melementsOfPCMDString\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpcmdString\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\";\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;31m#elementsOfPCMDString =(pcmdString)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'split'"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(fieldDict), fieldDict.items()\n",
      " \n",
      "if True:\n",
      "    isRealPCMD, sparkMaster, measDir, caseId, rnpId = getBasicConfigInfo() \n",
      "    print sparkMaster\n",
      "sparkAppName = 'PCMDMiner' + uuid.uuid1().hex\n",
      "sparkConf = (SparkConf()\n",
      "\t       .setMaster(sparkMaster)\n",
      "    \t       .setAppName(sparkAppName)\n",
      "    \t       .set('spark.scheduler.mode', 'FAIR'))\n",
      "\n",
      "#sc = SparkContext(conf = sparkConf)\n",
      "pcmdStrings = sc.textFile('sample')\n",
      "\n",
      "cellStats = pcmdStrings\\\n",
      "\t\t.flatMap(lambda x: mapRealPCMDString(x)) \\\n",
      "\t    .reduceByKey(lambda x, y: reduceToSingleStat(x, y)) \\\n",
      "\t\t.collect()\n",
      "sc.stop()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'fieldDict' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-7-0239f26f1c3e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfieldDict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfieldDict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0misRealPCMD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparkMaster\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeasDir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaseId\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrnpId\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetBasicConfigInfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0msparkMaster\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mNameError\u001b[0m: name 'fieldDict' is not defined"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Created by Supratim Deb on March 20, 2014\n",
      "\"\"\"\n",
      "This is a pyspark code for generating cell statistics from PCMD data\n",
      "\"\"\"\n",
      "\n",
      "from pyspark import SparkContext, SparkConf\n",
      "from collections import defaultdict\n",
      "import sys, operator, math, imp, os, uuid, ConfigParser, pyodbc\n",
      "import datetime as dt\n",
      "from multiprocessing import Pool\n",
      "import itertools as it\n",
      "import threading\n",
      "import networkx as nx\n",
      "import matplotlib . pyplot as plt\n",
      "\n",
      "#Max cores per worker\n",
      "SPARK_CORES_MAX = 3\n",
      "\n",
      "\n",
      "#Constants for synthetic pcmd string\n",
      "STRING_INDEX_FIRST_CELL = 4\n",
      "STRING_INDEX_NUM_CELLS = 3\n",
      "NUM_MEAS_STATISTICS = 6\n",
      "\n",
      "#Constants for real pcmd string\n",
      "CONFIG_FILE = 'config.ini'\n",
      "FIELD_SERVING_CELL_ID_PRIMARY = 21\n",
      "FIELD_UE_LOCATION_CAPABILITY = 158\n",
      "FIELD_CELL_ID = 131\n",
      "START_CHAR_MEAS = '['\n",
      "END_CHAR_PCMD = '|'\n",
      "LENGTH_MEAS_DATA = 4\n",
      "FIELD_CELL_ID_MEAS = 2\n",
      "FIELD_RSRP_MEAS = 3\n",
      "RSRP_MIN = -140.0\n",
      "DATETIME_FORMAT_PCMD_FILENAME = '%Y-%m-%d.%H_%M'\n",
      "INT_THRESHOLD = 0.09\n",
      "\n",
      "\n",
      "#Constant strings for outpul file string\n",
      "MEAS_STRINGS = ['MeanServer', 'MeanNeighbor', 'VarianceServer', 'CovarianceNeighbor', 'VarianceNeighbor']\n",
      "STRING_AVG_SERVER_RSRP = 'MeanServer'\n",
      "STRING_VAR_SERVER_RSRP = 'VarianceServer'\n",
      "STRING_AVG_NGHBR_RSRP = 'MeanNeighbor'\n",
      "STRING_VAR_NGHBR_RSRP = 'VarianceNeighbor'\n",
      "STRING_COVAR_RSRP = 'CovarianceNeighbor'\n",
      "\n",
      "\n",
      "#def computeCellStatsForManyMeasFiles(startTime, timeWindowInMinutes, isRealPCMD, sparkMaster, measDir):\n",
      "def parallelyComputeCellStatsForManyMeasFiles(startTime, timeWindowInMinutes, isRealPCMD, sparkMaster, measDir):\n",
      "\t\n",
      "\ttimelyFiles = getTimelyFilesFromHDFS(startTime, timeWindowInMinutes, measDir)\n",
      "\tlistCellStats = []\n",
      "\n",
      "\tpool = Pool()\n",
      "\tfileCellStats = pool.map(computeCellStatsForOneMeasFile_star, \\\n",
      "\t\t\t\t\t\t\t it.izip(it.repeat(sparkMaster), it.repeat(isRealPCMD), timelyFiles))\n",
      "\tpool.close()\n",
      "\tpool.join()\n",
      "\tlistCellStats = list(it.chain(*fileCellStats))\n",
      "\n",
      "\tsparkAppName = 'PCMDMiner' \n",
      "\tsc = SparkContext(sparkMaster, sparkAppName)\n",
      "\trddCellStats = sc.parallelize(listCellStats)\n",
      "\tcellStats = rddCellStats \\\n",
      "\t\t\t\t.reduceByKey(lambda x, y: reduceToSingleStat(x, y)) \\\n",
      "\t            .map(lambda x: (x[0], toCovarMatrix(x[1]))) \\\n",
      "\t            .sortByKey() \\\n",
      "\t            .collect()\n",
      "\tsc.stop()\n",
      "\n",
      "\treturn cellStats\n",
      "\n",
      "\n",
      "def computeCellStatsForManyMeasFiles(startTime, timeWindowInMinutes, isRealPCMD, sparkMaster, measDir):\n",
      "\ttimelyFiles = getTimelyFilesFromHDFS(startTime, timeWindowInMinutes, measDir)\n",
      "\tlistCellStats = []\n",
      "\tfor fn in timelyFiles:\n",
      "\t\tcs = computeCellStatsForOneMeasFile(sparkMaster, isRealPCMD, fn)\n",
      "\t\tlistCellStats.extend(cs)\n",
      "\tsparkAppName = 'PCMDMiner' \n",
      "\treturn listCellStats\n",
      "\tsc = SparkContext(sparkMaster, sparkAppName)\n",
      "\trddCellStats = sc.parallelize(listCellStats)\n",
      "\tcellStats = rddCellStats \\\n",
      "\t\t\t.reduceByKey(lambda x, y: reduceToSingleStat(x, y)) \\\n",
      "\t\t\t.sortByKey() \\\n",
      "\t\t\t.collect()\n",
      "\tsc.stop()\n",
      "\n",
      "\treturn cellStats\n",
      "\n",
      "\n",
      "\"\"\"\n",
      "the following is a wrapper around computeCellStatsForOneMeasFile with all arguments\n",
      "put in a single list. this is required for parrallel processing of multiple files.\n",
      "\"\"\"\n",
      "def computeCellStatsForOneMeasFile_star(params):\n",
      "\treturn(computeCellStatsForOneMeasFile(*params))\n",
      "\n",
      "\n",
      "def computeCellStatsForOneMeasFile(sparkMaster, isRealPCMD, measFileName):\n",
      "\tsparkAppName = 'PCMDMiner' + uuid.uuid1().hex\n",
      "\tsparkConf = (SparkConf()\n",
      "\t       .setMaster(sparkMaster)\n",
      "    \t       .setAppName(sparkAppName)\n",
      "    \t       .set('spark.scheduler.mode', 'FAIR'))\n",
      "\n",
      "\tsc = SparkContext(conf = sparkConf)\n",
      "\tpcmdStrings = sc.textFile(measFileName)\n",
      "#\tcellStats = pcmdStrings\\\n",
      "#\t            .flatMap(lambda x: mapPCMDString(isRealPCMD, x)) \\\n",
      "#\t            .reduceByKey(lambda x, y: reduceToSingleStat(x, y)) \\\n",
      "#\t            .collect()\n",
      "\tcellStats = pcmdStrings\\\n",
      "\t\t.flatMap(lambda x: mapPCMDString(isRealPCMD, x)) \\\n",
      "\t        .reduceByKey(lambda x, y: reduceToSingleStat(x, y)) \\\n",
      "\t\t.collect()\n",
      "\tsc.stop()\n",
      "\t#debug\n",
      "\t            \n",
      "\treturn cellStats\n",
      "\n",
      "\n",
      "\n",
      "def getTimelyFilesFromHDFS(startTime, timeWindowInMinutes, measDirName):\n",
      "\thadoopCommand = 'hadoop fs -ls %s/' % measDirName\n",
      "\tfullListings = os.popen(hadoopCommand).read().split('\\n')\n",
      "\tfileNames = [x.split(' ')[-1].split('/')[-1] for x in fullListings][1:-1]\n",
      "\ttimelyFiles = []\n",
      "\tdtStartTime = dt.datetime.strptime(startTime, DATETIME_FORMAT_PCMD_FILENAME)\n",
      "\tdtEndTime = dtStartTime + dt.timedelta(0, timeWindowInMinutes * 60)\n",
      "\tfor fn in fileNames:\n",
      "\t\tfileCreateTimeString = '.'.join(fn.split('.')[:2])\n",
      "\t\tdtFileCreateTime = dt.datetime.strptime(fileCreateTimeString, DATETIME_FORMAT_PCMD_FILENAME)\n",
      "\t\tif ((dtFileCreateTime >= dtStartTime) and (dtFileCreateTime <= dtEndTime)):\n",
      "\t\t\tif (measDirName[-1] != '/'):\n",
      "\t\t\t\tsep = '/'\n",
      "\t\t\telse:\n",
      "\t\t\t\tsep = ''\n",
      "\t\t\ttimelyFiles.append(measDirName + sep + fn)\n",
      "\t\t\n",
      "\treturn timelyFiles\n",
      "\n",
      "\n",
      "\n",
      "def mapPCMDString(isRealPCMD, pcmdString):\n",
      "\tif isRealPCMD:\n",
      "\t\treturn mapRealPCMDString(pcmdString)\n",
      "\telse:\n",
      "\t\treturn mapSyntheticPCMDString(pcmdString)\n",
      "\n",
      "\n",
      "\n",
      "\"\"\"\n",
      "The following map function creates (key, value) pairs where \n",
      "key = (serving_cell, neighbor_cell) which is 2-tuple\n",
      "value = (server_RSRP, nghbr_RSRP, server_RSRP^2, server_RSRP*nghbr_RSRP, nghbr_RSRP^2, 1)\n",
      "which is a 5-tuple.\n",
      "This representation helps us aggregate the values in the reduce function.\n",
      "\"\"\"\n",
      "def mapSyntheticPCMDString(pcmdString):\n",
      "\telementsOfPCMDString = pcmdString.split(\",\")\n",
      "\tservingCell = elementsOfPCMDString[0]\n",
      "\tserverRSRP = max(0, float(elementsOfPCMDString[STRING_INDEX_FIRST_CELL + 1]) - RSRP_MIN)\n",
      "\tlistOfMeasurements = []\n",
      "\tfor count in range(0,int(elementsOfPCMDString[STRING_INDEX_NUM_CELLS])):\n",
      "\t\tnghbrCell = elementsOfPCMDString[STRING_INDEX_FIRST_CELL + 2*count]\n",
      "\t\tnghbrRSRP = max(0, float(elementsOfPCMDString[STRING_INDEX_FIRST_CELL + 2*count + 1]) -RSRP_MIN)\n",
      "\t\tlistOfMeasurements.append((\n",
      "\t\t\t(servingCell, nghbrCell),\\\n",
      "\t\t\t(serverRSRP, nghbrRSRP, serverRSRP*serverRSRP,\\\n",
      "\t\t\t serverRSRP*nghbrRSRP, nghbrRSRP*nghbrRSRP, 1)\\\n",
      "\t\t\t))\n",
      "\n",
      "\treturn listOfMeasurements\n",
      "\n",
      "\"\"\"\n",
      "this function retrieves all measurement strings from a pcmd string \n",
      "\"\"\"\n",
      "def getListOfMeasurementRecordsFromPCMDString(pcmdString):\n",
      "\telementsOfPCMDString = pcmdString.split(\";\")\n",
      "\tservingCell = elementsOfPCMDString[FIELD_SERVING_CELL_ID_PRIMARY - 1]\n",
      "\t#RSRP is just one field needed.\n",
      "\tif START_CHAR_MEAS not in pcmdString:\n",
      "\t\treturn servingCell, []\n",
      "\n",
      "\tstartOfMeasRecords = pcmdString.index(START_CHAR_MEAS) + 1\n",
      "\tendOfMeasRecords = pcmdString.index(END_CHAR_PCMD)\n",
      "\tallMeasRecords = (pcmdString[startOfMeasRecords : endOfMeasRecords]).split(\";\")\n",
      "\tlistOfMeasRecords = []\n",
      "\tcount = 0\n",
      "\twhile (count < len(allMeasRecords)):\n",
      "\t\tstartOfThisMeasRecord = count\n",
      "\t\tlengthOfThisMeasRecord = int(allMeasRecords[count]) * LENGTH_MEAS_DATA + 1\n",
      "\t\tendOfThisMeasRecord = startOfThisMeasRecord + lengthOfThisMeasRecord\n",
      "\t\tlistOfMeasRecords.append(allMeasRecords[startOfThisMeasRecord : endOfThisMeasRecord])\n",
      "\t\tcount = endOfThisMeasRecord\n",
      "\t#Add an additional return value that will include additional PCMD fields\n",
      "\t#Need to correct the syntax to combine these two structures into the listOfllMeasRecords\n",
      "\treturn servingCell, listOfMeasRecords\n",
      "\n",
      "\n",
      "\"\"\"\n",
      "The following function reads a pcmd measurement string and retrieves the values in\n",
      "a dictionary format with keys being cellids and values being RSRPs \n",
      "\"\"\"\n",
      "def getRSRPDictFromMeasRecord(servingCell, measRecord):\n",
      "\tnumCellsInMeasRecord = int(measRecord[0])\n",
      "\tnumMeasData = int((len(measRecord) - 1)/ LENGTH_MEAS_DATA)\n",
      "\t\"\"\" create a dictionary with rsrp measurements in this record \"\"\"\n",
      "\tindex = 0\n",
      "\trsrpMeasVal = defaultdict(float) \n",
      "\n",
      "\tfor count in range(0, numMeasData):\n",
      "\t\tthisMeasData = measRecord[1+count*LENGTH_MEAS_DATA : 1+(count + 1)*LENGTH_MEAS_DATA]\n",
      "\t\tthisCell = thisMeasData[FIELD_CELL_ID_MEAS - 1]\n",
      "\t\t#Apparently the RSRP was stored as a string as well and needs to be converted\n",
      "\t\tthisRSRPString = thisMeasData[FIELD_RSRP_MEAS - 1]\n",
      "\t\tif (thisCell == '') or (thisRSRPString == ''):\n",
      "\t\t\tcontinue\n",
      "\t\telse:\n",
      "\t\t\t#This line creates a dictionary based on the cell found in the measurement data. \n",
      "\t\t\trsrpMeasVal[thisCell] = float(thisRSRPString)\n",
      "\t#Note servingCell was passed to this function but not used.\n",
      "\treturn rsrpMeasVal\n",
      "\n",
      "\n",
      "\"\"\"\n",
      "define a commutative and associative function for combining aggregate statistics\n",
      "this is used by reduce function in the code later\n",
      "\"\"\"\n",
      "def reduceToSingleStat(stat1, stat2):\n",
      "\tif stat2.share[1] < NUM_MEAS_STATISTICS -1:\n",
      "\t\treturn []\n",
      "\tsumMeasCount = stat1[NUM_MEAS_STATISTICS-1] + stat2[NUM_MEAS_STATISTICS-1]\n",
      "\twtStat1 = 1.0 * stat1[NUM_MEAS_STATISTICS-1] / sumMeasCount\n",
      "\twtStat2 = 1.0 * stat2[NUM_MEAS_STATISTICS-1] / sumMeasCount\n",
      "\treducedStat = [0] * NUM_MEAS_STATISTICS\n",
      "\tfor index in range(0, NUM_MEAS_STATISTICS - 1):\n",
      "\t\treducedStat[index] = wtStat1 * stat1[index] + wtStat2 * stat2[index]\n",
      "\treducedStat[NUM_MEAS_STATISTICS-1] = sumMeasCount\n",
      "\treturn tuple(reducedStat)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "def toCovarMatrix(stat):\n",
      "\tparams = [0] * NUM_MEAS_STATISTICS\n",
      "\tfor index in [0, 1, NUM_MEAS_STATISTICS-1]:\n",
      "\t\tparams[index] = stat[index]\n",
      "\tparams[2] = stat[2] - stat[0]*stat[0]\n",
      "\tparams[3] = stat[3] - stat[0]*stat[1]\n",
      "\tparams[4] = stat[4] - stat[1]*stat[1]\n",
      "\treturn tuple(params)\n",
      "\n",
      "\n",
      "def saveAsFile(outputFile, cellStats, caseId, rnpId):\n",
      "\twith open(outputFile + '.txt', 'w') as opf:\n",
      "\t\tfor cs in cellStats:\n",
      "\t\t\top_string = '{:16s}  {:16s}   '.format(cs[0][0], cs[0][1])\n",
      "\t\t\tfor i in range(0, NUM_MEAS_STATISTICS - 1):\n",
      "\t\t\t\top_string =  op_string + '{:>10s}'.format('{:4.2f}'.format(cs[1][i]))\n",
      "\t\t\top_string =  op_string +\\\n",
      "\t\t\t\t '{:>8s}'.format('{:4d}'.format(cs[1][NUM_MEAS_STATISTICS-1]))\n",
      "\t\t\topf.write(op_string + '\\n')\n",
      "\n",
      "\n",
      "\tallDBRowsAsStrings = getAllDBRowsAsStrings(cellStats, caseId, rnpId)\n",
      "\twith open(outputFile + '.csv', 'w') as opf:\n",
      "\t\tfor measString in allDBRowsAsStrings:\n",
      "\t\t\topf.write(measString + '\\n')\n",
      "\n",
      "\treturn\n",
      "\n",
      "\n",
      "def getAllDBRowsAsStrings(cellStats, caseId, rnpId):\n",
      "\tallDBRowsAsStrings = []\n",
      "\tfor cs in cellStats:\n",
      "\t\tcommonString = \"%d, %d\" % (caseId, rnpId)\n",
      "\t\tmeasStats = [RSRP_MIN + cs[1][0], RSRP_MIN + cs[1][1], cs[1][2], cs[1][3], cs[1][4], cs[1][5]]\n",
      "\t\tfor i in range(len(MEAS_STRINGS)):\n",
      "\t\t\tmeasType = MEAS_STRINGS[i]\n",
      "\t\t\tmeasuredCells= (cs[0][0], cs[0][1])\n",
      "\t\t\tmeasString = \"%s, '%s', '%s', '%s', '%s', %s, %s\"\\\n",
      "\t\t\t             % (commonString, measType, cs[0][0], measuredCells[0], measuredCells[1],\n",
      "\t\t\t                str(measStats[i]), str(measStats[5]))\n",
      "\t\t\tallDBRowsAsStrings.append('(' + measString + ')')\n",
      "\treturn allDBRowsAsStrings\n",
      "\n",
      "\n",
      "def saveToDatabase(cellStats, caseId, rnpId):\n",
      "\tconStr = getDBConnStringConfig()\n",
      "\tcnx = pyodbc.connect(conStr)\n",
      "\tcursor = cnx.cursor()\n",
      "\tcnf = ConfigParser.ConfigParser()\n",
      "\tcnf.read(CONFIG_FILE)\n",
      "\ttableName = dict(cnf.items('DB_TABLE'))['name']\n",
      "\ttableOverwrite = dict(cnf.items('DB_TABLE'))['overwrite']\n",
      "\tif tableOverwrite == 'y':\n",
      "\t\tdelStr = 'DELETE FROM %s WHERE Case_Id = %d AND RNP_Simulation_Id = %d' % (tableName, caseId, rnpId)\n",
      "\t\tcursor.execute(delStr)\n",
      "\t\tprint ('Deleted %d from DB: ' % cursor.rowcount) + delStr\n",
      "\t\tcnx.commit()\n",
      "\n",
      "\n",
      "\tallDBRowsAsStrings = getAllDBRowsAsStrings(cellStats, caseId, rnpId)\n",
      "\tfor dbRowString in allDBRowsAsStrings:\n",
      "\t\tinsertStr = \"INSERT INTO RSRPJointGaussianParams VALUES %s\" % dbRowString\n",
      "\t\tcursor.execute(insertStr)\n",
      "\tcnx.commit()\n",
      "\n",
      "\tcnx.close()\n",
      "\treturn\n",
      "\n",
      "\n",
      "def getDBConnStringConfig():\n",
      "\tconStr = r''\n",
      "\tcnf = ConfigParser.ConfigParser()\n",
      "\tcnf.read(CONFIG_FILE)\n",
      "\tfor option in cnf.items('DATABASE'):\n",
      "\t\tconStr += '%s=%s;' %  option\n",
      "\treturn conStr.rstrip(';')\n",
      "\n",
      "\n",
      "def getBasicConfigInfo():\n",
      "\tcnf = ConfigParser.ConfigParser()\n",
      "\tcnf.read(CONFIG_FILE)\n",
      "\tisRealPCMD = cnf.getint('BASIC', 'REAL_PCMD')\n",
      "\tsparkMaster = cnf.get('BASIC', 'SPARK_MASTER')\n",
      "\tmeasDir = cnf.get('BASIC', 'HADOOP_PCMD_DIR')\n",
      "\tcaseId = cnf.getint('BASIC', 'CASE_ID')\n",
      "\trnpId = cnf.getint('BASIC', 'RNP_SIM_ID')\n",
      "\treturn isRealPCMD, sparkMaster, measDir, caseId, rnpId\n",
      "\n",
      "\n",
      "def createClusters(cellStats):\n",
      "\tcellGraph = nx.DiGraph()\n",
      "\tcellNodes =set([])\n",
      "\tcellEdges = []\n",
      "\tfor cs in cellStats:\n",
      "\t\tcellNodes = cellNodes.union(set(cs[0]))\n",
      "\n",
      "\tcellTotalWeight = defaultdict(int)\n",
      "\tfor node in cellNodes:\n",
      "\t\tcellTotalWeight[node] = sum([x[1][5] for x in cellStats if x[0][0] == node and x[0][1] != node])\n",
      "\t\t#print '%s : %d' % (node, cellTotalWeight[node])\n",
      "\t\t#sys.stdin.read(1)\n",
      "\n",
      "\tfor cs in cellStats:\n",
      "\t\tif ((cs[0][0] != cs[0][1]) and (cs[1][5] > cellTotalWeight[cs[0][0]] * INT_THRESHOLD)):\n",
      "\t\t\tcellEdges.append(cs[0])\n",
      "\t\t\t#cellEdges.append((cs[0][0], cs[0][1], cs[1][5]))\n",
      "\n",
      "\tcellGraph.add_nodes_from(list(cellNodes))\n",
      "\tcellGraph.add_edges_from(cellEdges)\n",
      "\tcomps = nx.connected_component_subgraphs(cellGraph.to_undirected())\n",
      "\tprint 'Nodes = %d, Edges = %d' % (cellGraph.number_of_nodes(), cellGraph.number_of_edges())\n",
      "\tind = 0\n",
      "\tfor sg in comps:\n",
      "\t\tind += 1\n",
      "\t\tprint '%d : %d , %d' % (ind, sg.number_of_nodes(), sg.number_of_edges())\n",
      "\n",
      "\treturn\n",
      "\n",
      "\n",
      "\t#########################################################\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}