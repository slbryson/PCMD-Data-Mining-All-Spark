{
 "metadata": {
  "name": "",
  "signature": "sha256:400c1c46d36a1cc93c8c5c0aea2b8eb3a19fedb83e0a97890e2bc2b182ddc890"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "spark_home = \"/usr/local/share/spark-0.9.0-incubating-bin-hadoop2\"\n",
      "os.environ['SPARK_HOME'] = spark_home\n",
      "import sys\n",
      "path_to_pyspark = os.path.join(spark_home,\"python\")\n",
      "sys.path.insert(0,path_to_pyspark)\n",
      "from pyspark import SparkContext, SparkConf\n",
      "from collections import defaultdict\n",
      "import sys, operator, math, imp, os, uuid, ConfigParser, pyodbc\n",
      "import datetime as dt\n",
      "from multiprocessing import Pool\n",
      "import itertools as it\n",
      "import threading\n",
      "import networkx as nx\n",
      "import numpy \n",
      "import matplotlib . pyplot as plt\n",
      "#Constants for real pcmd string\n",
      "CONFIG_FILE = 'config.ini'\n",
      "FIELD_SERVING_CELL_ID_PRIMARY = 21\n",
      "FIELD_UE_LOCATION_CAPABILITY = 158\n",
      "FIELD_CELL_ID = 131\n",
      "START_CHAR_MEAS = '['\n",
      "END_CHAR_PCMD = '|'\n",
      "LENGTH_MEAS_DATA = 4\n",
      "FIELD_CELL_ID_MEAS = 2\n",
      "FIELD_RSRP_MEAS = 3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getBasicConfigInfo():\n",
      "\tcnf = ConfigParser.ConfigParser()\n",
      "\tcnf.read(CONFIG_FILE)\n",
      "\tisRealPCMD = cnf.getint('BASIC', 'REAL_PCMD')\n",
      "\tsparkMaster = cnf.get('BASIC', 'SPARK_MASTER')\n",
      "\tmeasDir = cnf.get('BASIC', 'HADOOP_PCMD_DIR')\n",
      "\tcaseId = cnf.getint('BASIC', 'CASE_ID')\n",
      "\trnpId = cnf.getint('BASIC', 'RNP_SIM_ID')\n",
      "\treturn isRealPCMD, sparkMaster, measDir, caseId, rnpId"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if True:\n",
      "    isRealPCMD, sparkMaster, measDir, caseId, rnpId = getBasicConfigInfo() \n",
      "    print sparkMaster\n",
      "sparkAppName = 'PCMDMiner' + uuid.uuid1().hex\n",
      "sparkAppName = 'PCMDMiner' + uuid.uuid1().hex\n",
      "sparkConf = (SparkConf()\n",
      "             .setMaster(sparkMaster)\n",
      "             .setAppName(sparkAppName)\n",
      "             .set('spark.scheduler.mode', 'FAIR'))\n",
      "#sc = SparkContext(conf = sparkConf)\n",
      "pcmdStrings = sc.textFile('sample')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "spark://192.168.122.1:7077\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Type of sc\", type(sc)\n",
      "r1 = sc.textFile('sample')\n",
      "r2 =r1.flatMap(lambda x: x.split(\";\"))\n",
      "r4 =r1.flatMap(lambda x: x.split())\n",
      "mysize = int(r4.count())\n",
      "print r2.take(3),r2.count(),'\\n',r4.take(1),r4.count(), \"mysize \", mysize\n",
      "myiter = list(range(1,mysize))\n",
      "\n",
      "r5 = r4.map(lambda x: [(x,i) for i in range(1,mysize)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Type of sc <class 'pyspark.context.SparkContext'>\n",
        "[u'6', u'87300844', u'311:480:fa4e:4f']"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6057 \n",
        "[u'6;87300844;311:480:fa4e:4f;-04:00;03:26;2014;45;76320870;34;14;0;1;100;;;35881205:087694:03;13477390096;311480099093477;e0f96785;;311:480:1486703;;;;;;;;;;;;;;;;;2001:4888:2011:b000:137:280:0:14;;;311:480:1486703;;;;;;;;;;3;;3;1;58;;;;;;;;;;;;;;;;;;;;;;;;;;;;186497;;;76319747;76320880;1;103;2;48;0;0;0;0;0;38;9;0;0;;;76320745;0;;;;;;;;0;0;0;0;1;0;0;1;0;0;1;0;0;0;0;3;-04:00;;;311:480:5dc4720;311:480:1486703;3;;6;;1;;;76319733;1;0;1891;0;0;0;0;0;;;;2;;76320755;76319940;76320745;2;;;;2;2;3;76320755;;0;;;;;;;2;;;;;;;;;;;;;;;0;;;;;;;;;;;;;;;;;;;;;;;;;;123;;;;;;;;;;;;0;0;;;;;1;;2001:4888:8000:fff0:137:200::;vzwims.mnc480.mcc311.gprs;;;2;5;;5;;;;;;;0;0;0;0;0;0;2;;;;;;;;;;;;0;;;2600:1001:8128:227e:0:17:ed59:8c01;2001:4888:8000:fff0:137:200::;vzwinternet.mnc480.mcc311.gprs;;;2;8;;6;;;;;;;4;164;3;24;0;15;2;;;;;;;;;;;;0;;;2600:1001:b118:ae79:0:17:ed59:8d01[1;344;311:480:5dc4720;24;23;2;344;311:480:5dc4720;24;24;344;311:480:1486703;40;|'] "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "20 mysize  20\n"
       ]
      }
     ],
     "prompt_number": 101
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r5.count()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "20"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Type of sc\", type(sc)\n",
      "r1 = sc.textFile('sample')\\\n",
      "    .flatMap(lambda x: x.split())\n",
      " \n",
      "\n",
      "#print \"r1 with first split\\n\" , r1.count(), r1.take(1)\n",
      "mysize = int(r1.count())\n",
      "mynew =range(mysize)\n",
      "\n",
      "for row in range(mysize):\n",
      "\n",
      "    mynew[row] = r1.take(i)\n",
      "print mynew[3]\n",
      "\n",
      "#print 'Now size',size(mynew), mynew[3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Type of sc <class 'pyspark.context.SparkContext'>\n",
        "[u'6;87300844;311:480:fa4e:4f;-04:00;03:26;2014;45;76320870;34;14;0;1;100;;;35881205:087694:03;13477390096;311480099093477;e0f96785;;311:480:1486703;;;;;;;;;;;;;;;;;2001:4888:2011:b000:137:280:0:14;;;311:480:1486703;;;;;;;;;;3;;3;1;58;;;;;;;;;;;;;;;;;;;;;;;;;;;;186497;;;76319747;76320880;1;103;2;48;0;0;0;0;0;38;9;0;0;;;76320745;0;;;;;;;;0;0;0;0;1;0;0;1;0;0;1;0;0;0;0;3;-04:00;;;311:480:5dc4720;311:480:1486703;3;;6;;1;;;76319733;1;0;1891;0;0;0;0;0;;;;2;;76320755;76319940;76320745;2;;;;2;2;3;76320755;;0;;;;;;;2;;;;;;;;;;;;;;;0;;;;;;;;;;;;;;;;;;;;;;;;;;123;;;;;;;;;;;;0;0;;;;;1;;2001:4888:8000:fff0:137:200::;vzwims.mnc480.mcc311.gprs;;;2;5;;5;;;;;;;0;0;0;0;0;0;2;;;;;;;;;;;;0;;;2600:1001:8128:227e:0:17:ed59:8c01;2001:4888:8000:fff0:137:200::;vzwinternet.mnc480.mcc311.gprs;;;2;8;;6;;;;;;;4;164;3;24;0;15;2;;;;;;;;;;;;0;;;2600:1001:b118:ae79:0:17:ed59:8d01[1;344;311:480:5dc4720;24;23;2;344;311:480:5dc4720;24;24;344;311:480:1486703;40;|']"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 146
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cellStats = pcmdStrings\\\n",
      "    .flatMap(lambda x: mapRealPCMDString(x)) \\ \n",
      "    .reduceByKey(lambda x, y: reduceToSingleStat(x, y)) \\\n",
      "    .collect()\n",
      "    \n",
      "sc.stop()\n",
      "\n",
      "servingCell, fieldDict = getFieldDictFromMeasRecord(pcmdString[0])\n",
      "print servingCell, fieldDict\n",
      "servingCell, fieldDict = getFieldDictFromMeasRecord(pcmdString[8])\n",
      "print fieldDict\n",
      "for row in range(0, 8):\n",
      "    print row\n",
      "    servingCell, fieldDict = getFieldDictFromMeasRecord(pcmdString[row])\n",
      "    print fieldDict\n",
      "print len(fieldDict), fieldDict.items()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}