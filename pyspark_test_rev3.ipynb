{
 "metadata": {
  "name": "",
  "signature": "sha256:fa05cfb7ea8f8a7f17910c2094811d8ddc830d144cbf0d22a1ed19caaa665529"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "spark_home = \"/usr/local/share/spark-0.9.0-incubating-bin-hadoop2\"\n",
      "os.environ['SPARK_HOME'] = spark_home\n",
      "import sys\n",
      "path_to_pyspark = os.path.join(spark_home,\"python\")\n",
      "sys.path.insert(0,path_to_pyspark)\n",
      "from pyspark import SparkContext, SparkConf\n",
      "from collections import defaultdict\n",
      "import sys, operator, math, imp, os, uuid, ConfigParser, pyodbc\n",
      "import datetime as dt\n",
      "from multiprocessing import Pool\n",
      "import itertools as it\n",
      "import threading\n",
      "import networkx as nx\n",
      "import numpy \n",
      "import matplotlib . pyplot as plt\n",
      "#Constants for real pcmd string\n",
      "CONFIG_FILE = 'config.ini'\n",
      "FIELD_SERVING_CELL_ID_PRIMARY = 21\n",
      "FIELD_UE_LOCATION_CAPABILITY = 158\n",
      "FIELD_CELL_ID = 131\n",
      "START_CHAR_MEAS = '['\n",
      "END_CHAR_PCMD = '|'\n",
      "LENGTH_MEAS_DATA = 4\n",
      "FIELD_CELL_ID_MEAS = 2\n",
      "FIELD_RSRP_MEAS = 3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getBasicConfigInfo():\n",
      "\tcnf = ConfigParser.ConfigParser()\n",
      "\tcnf.read(CONFIG_FILE)\n",
      "\tisRealPCMD = cnf.getint('BASIC', 'REAL_PCMD')\n",
      "\tsparkMaster = cnf.get('BASIC', 'SPARK_MASTER')\n",
      "\tmeasDir = cnf.get('BASIC', 'HADOOP_PCMD_DIR')\n",
      "\tcaseId = cnf.getint('BASIC', 'CASE_ID')\n",
      "\trnpId = cnf.getint('BASIC', 'RNP_SIM_ID')\n",
      "\treturn isRealPCMD, sparkMaster, measDir, caseId, rnpId"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if True:\n",
      "    isRealPCMD, sparkMaster, measDir, caseId, rnpId = getBasicConfigInfo() \n",
      "    print sparkMaster\n",
      "sparkAppName = 'PCMDMiner' + uuid.uuid1().hex\n",
      "sparkAppName = 'PCMDMiner' + uuid.uuid1().hex\n",
      "sparkConf = (SparkConf()\n",
      "             .setMaster(sparkMaster)\n",
      "             .setAppName(sparkAppName)\n",
      "             .set('spark.scheduler.mode', 'FAIR'))\n",
      "#sc = SparkContext(conf = sparkConf)\n",
      "pcmdStrings = sc.textFile('sample')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "spark://192.168.122.1:7077\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Type of sc\", type(sc)\n",
      "field = 287\n",
      "r1 = sc.textFile('sample')\\\n",
      "    .map(lambda x: getField(x,field))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Type of sc <class 'pyspark.context.SparkContext'>\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<b>The point and success of the small snippet below is that getField will arbritraly return a field by number from PCDM.  It will not do much checking for example if a portion of the record exists like the check for \"|\" indicating RSRP"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "field = 287\n",
      "r2 = sc.textFile('sample')\\\n",
      "    .map(lambda x: getField(x,field))\n",
      "    \n",
      "    \n",
      "def getField(s, field):\n",
      "        words = s.split(\";\")\n",
      "        if len(words) < field:\n",
      "            return len(words),-15\n",
      "        else:\n",
      "            return int(words[8-1]),float(words[field-1])\n",
      "\n",
      "\n",
      "print r2.take(r2.count())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(76320870, 24.0), (76320889, 298.0), (76320846, 0.0), (76320860, 1.0), (76320869, 3.0), (269, -15), (76320866, 0.0), (76320867, 5.0), (76320880, 4.0), (76320880, 0.0), (76320880, 0.0), (76320880, 0.0), (76320880, 0.0), (76320803, 0.0), (76320880, 0.0), (76320880, 1.0), (76320899, 0.0), (269, -15), (76320891, 4.0), (76320890, 0.0)]\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = 'blue;red;\"45\"'\n",
      "print x\n",
      "x.split(\";\")\n",
      "print x\n",
      "print x[10]\n",
      "print r2.take(r2.count())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "blue;red;\"45\"\n",
        "blue;red;\"45\"\n",
        "4\n",
        "[(u'76320870', 24.0), (u'76320889', 298.0), (u'76320846', 0.0), (u'76320860', 1.0), (u'76320869', 3.0), (269, -15), (u'76320866', 0.0), (u'76320867', 5.0), (u'76320880', 4.0), (u'76320880', 0.0), (u'76320880', 0.0), (u'76320880', 0.0), (u'76320880', 0.0), (u'76320803', 0.0), (u'76320880', 0.0), (u'76320880', 1.0), (u'76320899', 0.0), (269, -15), (u'76320891', 4.0), (u'76320890', 0.0)]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}