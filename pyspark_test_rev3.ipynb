{
 "metadata": {
  "name": "",
  "signature": "sha256:1021f05f51e8f24bab64f69e1b176b4c7ef7278a1408fa0472cbfa0f6978f402"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "spark_home = \"/usr/local/share/spark-0.9.0-incubating-bin-hadoop2\"\n",
      "os.environ['SPARK_HOME'] = spark_home\n",
      "import sys\n",
      "path_to_pyspark = os.path.join(spark_home,\"python\")\n",
      "sys.path.insert(0,path_to_pyspark)\n",
      "from pyspark import SparkContext, SparkConf\n",
      "from collections import defaultdict\n",
      "import sys, operator, math, imp, os, uuid, ConfigParser, pyodbc\n",
      "import datetime as dt\n",
      "from multiprocessing import Pool\n",
      "import itertools as it\n",
      "import threading\n",
      "import networkx as nx\n",
      "import numpy \n",
      "import matplotlib . pyplot as plt\n",
      "#Constants for real pcmd string\n",
      "CONFIG_FILE = 'config.ini'\n",
      "FIELD_SERVING_CELL_ID_PRIMARY = 21\n",
      "FIELD_UE_LOCATION_CAPABILITY = 158\n",
      "FIELD_CELL_ID = 131\n",
      "START_CHAR_MEAS = '['\n",
      "END_CHAR_PCMD = '|'\n",
      "LENGTH_MEAS_DATA = 4\n",
      "FIELD_CELL_ID_MEAS = 2\n",
      "FIELD_RSRP_MEAS = 3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getBasicConfigInfo():\n",
      "\tcnf = ConfigParser.ConfigParser()\n",
      "\tcnf.read(CONFIG_FILE)\n",
      "\tisRealPCMD = cnf.getint('BASIC', 'REAL_PCMD')\n",
      "\tsparkMaster = cnf.get('BASIC', 'SPARK_MASTER')\n",
      "\tmeasDir = cnf.get('BASIC', 'HADOOP_PCMD_DIR')\n",
      "\tcaseId = cnf.getint('BASIC', 'CASE_ID')\n",
      "\trnpId = cnf.getint('BASIC', 'RNP_SIM_ID')\n",
      "\treturn isRealPCMD, sparkMaster, measDir, caseId, rnpId"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if True:\n",
      "    isRealPCMD, sparkMaster, measDir, caseId, rnpId = getBasicConfigInfo() \n",
      "    print sparkMaster\n",
      "sparkAppName = 'PCMDMiner' + uuid.uuid1().hex\n",
      "sparkAppName = 'PCMDMiner' + uuid.uuid1().hex\n",
      "sparkConf = (SparkConf()\n",
      "             .setMaster(sparkMaster)\n",
      "             .setAppName(sparkAppName)\n",
      "             .set('spark.scheduler.mode', 'FAIR'))\n",
      "#sc = SparkContext(conf = sparkConf)\n",
      "pcmdStrings = sc.textFile('sample')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "spark://192.168.122.1:7077\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Type of sc\", type(sc)\n",
      "field = 287\n",
      "r1 = sc.textFile('sample')\\\n",
      "    .map(lambda x: getField(x,field))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Type of sc <class 'pyspark.context.SparkContext'>\n"
       ]
      }
     ],
     "prompt_number": 120
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r5 = r1.reduce(lambda x, y: x+y)\n",
      "output = r1.collect()\n",
      "print type(r5), output[1], r5\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<type 'tuple'> (u'76320889', 298.0) (u'76320890', 0.0, u'76320891', 4.0, 269, -15, u'76320899', 0.0, u'76320880', 1.0, u'76320880', 0.0, u'76320803', 0.0, u'76320880', 0.0, u'76320880', 0.0, u'76320880', 0.0, u'76320880', 0.0, u'76320880', 4.0, u'76320867', 5.0, u'76320866', 0.0, 269, -15, u'76320869', 3.0, u'76320860', 1.0, u'76320846', 0.0, u'76320889', 298.0, u'76320870', 24.0)\n"
       ]
      }
     ],
     "prompt_number": 123
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Type of sc\", type(sc)\n",
      "field = 287\n",
      "r2 = sc.textFile('sample')\\\n",
      "    .map(lambda x: getField(x,field)) \n",
      "def getField(s, field):\n",
      "        words = s.split(\";\")\n",
      "        if len(words) < field:\n",
      "            return len(words),-15\n",
      "        else:\n",
      "            return words[8-1],float(words[field-1])\n",
      "\n",
      "\n",
      "print r2.take(5), type(r2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Type of sc <class 'pyspark.context.SparkContext'>\n",
        "[(u'76320870', 24.0), (u'76320889', 298.0), (u'76320846', 0.0), (u'76320860', 1.0), (u'76320869', 3.0)]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " <class 'pyspark.rdd.PipelinedRDD'>\n"
       ]
      }
     ],
     "prompt_number": 102
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = 'blue;red;\"45\"'\n",
      "print x\n",
      "x.split(\";\")\n",
      "print x\n",
      "print x[10]\n",
      "print r2.take(r2.count())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "blue;red;\"45\"\n",
        "blue;red;\"45\"\n",
        "4\n",
        "[(u'76320870', 24.0), (u'76320889', 298.0), (u'76320846', 0.0), (u'76320860', 1.0), (u'76320869', 3.0), (269, -15), (u'76320866', 0.0), (u'76320867', 5.0), (u'76320880', 4.0), (u'76320880', 0.0), (u'76320880', 0.0), (u'76320880', 0.0), (u'76320880', 0.0), (u'76320803', 0.0), (u'76320880', 0.0), (u'76320880', 1.0), (u'76320899', 0.0), (269, -15), (u'76320891', 4.0), (u'76320890', 0.0)]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 101
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cellStats = pcmdStrings\\\n",
      "    .flatMap(lambda x: mapRealPCMDString(x)) \\ \n",
      "    .reduceByKey(lambda x, y: reduceToSingleStat(x, y)) \\\n",
      "    .collect()\n",
      "    \n",
      "sc.stop()\n",
      "\n",
      "servingCell, fieldDict = getFieldDictFromMeasRecord(pcmdString[0])\n",
      "print servingCell, fieldDict\n",
      "servingCell, fieldDict = getFieldDictFromMeasRecord(pcmdString[8])\n",
      "print fieldDict\n",
      "for row in range(0, 8):\n",
      "    print row\n",
      "    servingCell, fieldDict = getFieldDictFromMeasRecord(pcmdString[row])\n",
      "    print fieldDict\n",
      "print len(fieldDict), fieldDict.items()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}